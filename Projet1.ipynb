{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "39aa995b",
      "metadata": {
        "id": "39aa995b"
      },
      "source": [
        "# Projet1 - AMS/Kaggle"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4baccbf1",
      "metadata": {
        "id": "4baccbf1"
      },
      "source": [
        "## Sébastien Coll - 300089305\n",
        "### Group 3"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "08e1bf53",
      "metadata": {
        "id": "08e1bf53"
      },
      "source": [
        "--------------------------------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "de2fff19",
      "metadata": {
        "id": "de2fff19"
      },
      "source": [
        "### Étape 1"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "82bb1ad0",
      "metadata": {
        "id": "82bb1ad0"
      },
      "source": [
        "#### a.\n",
        "Jeu de données choisi: https://www.kaggle.com/datasets/yasserh/wine-quality-dataset\n",
        "Ce jeu de données en est un de classification multiclasse, car le résultat peut être un nombre entre 0 et 10 déterminant la qualité des vins. Cependant, il pourrait être possible de rendre ce jeu de données en classification binaire en changeant la qualité par un attribut binaire (par exemple, > 6 est bon <= 6 est pas bon). *\n",
        "#### b.\n",
        "Oui, ce jeu de données à une application particulière. Il vise à prédire la qualité des vins en se fiant sur différentes caractéristiques physicochimique de ceux-ci.\n",
        "\n",
        "*J'ai décidé de le convertir en classification binaire afin d'avoir des résultats plus constants et précis."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5b741638",
      "metadata": {
        "id": "5b741638"
      },
      "source": [
        "### Étape 2\n",
        "#### a.\n",
        "Ce jeu de données a beaucoup d'exemple d'entrainement, ce qui rendra la prédiction encore plus précise. Il contient exactement 1 143 exemples d'entrainement. Ce nombre d'exemple d'entrainement est bon pour ce genre de travail, étant donné qu'il comporte suffisament d'exemple, mais qu'il garde tout de même le temps de traitement dans des temps raisonnables.\n",
        "\n",
        "Il y a 13 attributs, fixed acidity, volatile acidity, citric acid, residual sugar, chlorides, free sulfur dioxide, total sulfur dioxide, density, pH, sulphates, alcohol et qualité.\n",
        "\n",
        "J'ai choisi ce jeu de données car les attributs sont très \"Straightforward\" et facile d'utilisation et de compréhension.\n",
        "\n",
        "Il n'y a pas de données manquantes dans le jeu de données. (Voir étape 5)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6e58998f",
      "metadata": {
        "id": "6e58998f"
      },
      "source": [
        "### Étape 3\n",
        "#### a.\n",
        "Tous les attributs présents dans le jeu de données sont présentes. Il ne semble pas manquer d'attributs dans celui-ci. Les attributs semblent regrouper l'ensemble des catégories nécéssaires pour pouvoir identifier la qualité du vin. On essaie de déterminer une corrélation entre les composantes chimiques d'un vin et sa qualité, tous les composantes chimiques semblent être listées.\n",
        "\n",
        "De plus, j'ai converti l'attribut de sortie en classification binaire afin d'avoir des résultats plus constants et précis, ainsi que de facilité la tâche et les résultats du projet en générale.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1aec737b",
      "metadata": {
        "id": "1aec737b"
      },
      "source": [
        "### Étape 4\n",
        "#### a.\n",
        "\n",
        "Ce jeu de données contient 11 attributs d'entrées:  \n",
        "\n",
        "Fixed acidity: attribut continue, utilisation de celle-ci telle quelle  \n",
        "Volatile acidity: attribut continue, utilisation de celle-ci telle quelle  \n",
        "Citric acid: attribut continue, utilisation de celle-ci telle quelle  \n",
        "Residual sugar: attribut continue, utilisation de celle-ci telle quelle  \n",
        "Chlorides: attribut continue, utilisation de celle-ci telle quelle  \n",
        "Free sulfur dioxide: attribut continue, utilisation de celle-ci telle quelle  \n",
        "Total sulfur dioxide: attribut continue, utilisation de celle-ci telle quelle  \n",
        "Density: attribut continue, utilisation de celle-ci telle quelle  \n",
        "pH: attribut continue, utilisation de celle-ci telle quelle  \n",
        "Sulphates: attribut continue, utilisation de celle-ci telle quelle  \n",
        "Alcohol: attribut continue, utilisation de celle-ci telle quelle    \n",
        "\n",
        "  \n",
        "Ce jeu de données contient 1 attributs de sortie:  \n",
        "\n",
        "Quality: attribut continue, utilisation de celle-ci telle quelle\n",
        "\n",
        "Étant donné que l'on garde tous les attributs telle quelle, il n'y aura pas de preprocessing nécéssaire pour ce dataset (si nous voulions le changer en classification binaire, changer l'attribut de qualité serait le seul changement nécéssaire)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "36467526",
      "metadata": {
        "id": "36467526"
      },
      "source": [
        "### Étape 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 944,
      "id": "b6555487",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        },
        "id": "b6555487",
        "outputId": "1b03ca6c-a7b4-4420-907a-37e6f46b03d3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
              "0            7.4              0.70         0.00             1.9      0.076   \n",
              "1            7.8              0.88         0.00             2.6      0.098   \n",
              "2            7.8              0.76         0.04             2.3      0.092   \n",
              "3           11.2              0.28         0.56             1.9      0.075   \n",
              "4            7.4              0.70         0.00             1.9      0.076   \n",
              "5            7.4              0.66         0.00             1.8      0.075   \n",
              "6            7.9              0.60         0.06             1.6      0.069   \n",
              "7            7.3              0.65         0.00             1.2      0.065   \n",
              "8            7.8              0.58         0.02             2.0      0.073   \n",
              "9            6.7              0.58         0.08             1.8      0.097   \n",
              "\n",
              "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
              "0                 11.0                  34.0   0.9978  3.51       0.56   \n",
              "1                 25.0                  67.0   0.9968  3.20       0.68   \n",
              "2                 15.0                  54.0   0.9970  3.26       0.65   \n",
              "3                 17.0                  60.0   0.9980  3.16       0.58   \n",
              "4                 11.0                  34.0   0.9978  3.51       0.56   \n",
              "5                 13.0                  40.0   0.9978  3.51       0.56   \n",
              "6                 15.0                  59.0   0.9964  3.30       0.46   \n",
              "7                 15.0                  21.0   0.9946  3.39       0.47   \n",
              "8                  9.0                  18.0   0.9968  3.36       0.57   \n",
              "9                 15.0                  65.0   0.9959  3.28       0.54   \n",
              "\n",
              "   alcohol  quality  \n",
              "0      9.4        5  \n",
              "1      9.8        5  \n",
              "2      9.8        5  \n",
              "3      9.8        6  \n",
              "4      9.4        5  \n",
              "5      9.4        5  \n",
              "6      9.4        5  \n",
              "7     10.0        7  \n",
              "8      9.5        7  \n",
              "9      9.2        5  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-060c880c-b749-4ae2-bfb0-932e60b2efe5\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fixed acidity</th>\n",
              "      <th>volatile acidity</th>\n",
              "      <th>citric acid</th>\n",
              "      <th>residual sugar</th>\n",
              "      <th>chlorides</th>\n",
              "      <th>free sulfur dioxide</th>\n",
              "      <th>total sulfur dioxide</th>\n",
              "      <th>density</th>\n",
              "      <th>pH</th>\n",
              "      <th>sulphates</th>\n",
              "      <th>alcohol</th>\n",
              "      <th>quality</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>7.4</td>\n",
              "      <td>0.70</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.9</td>\n",
              "      <td>0.076</td>\n",
              "      <td>11.0</td>\n",
              "      <td>34.0</td>\n",
              "      <td>0.9978</td>\n",
              "      <td>3.51</td>\n",
              "      <td>0.56</td>\n",
              "      <td>9.4</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>7.8</td>\n",
              "      <td>0.88</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2.6</td>\n",
              "      <td>0.098</td>\n",
              "      <td>25.0</td>\n",
              "      <td>67.0</td>\n",
              "      <td>0.9968</td>\n",
              "      <td>3.20</td>\n",
              "      <td>0.68</td>\n",
              "      <td>9.8</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>7.8</td>\n",
              "      <td>0.76</td>\n",
              "      <td>0.04</td>\n",
              "      <td>2.3</td>\n",
              "      <td>0.092</td>\n",
              "      <td>15.0</td>\n",
              "      <td>54.0</td>\n",
              "      <td>0.9970</td>\n",
              "      <td>3.26</td>\n",
              "      <td>0.65</td>\n",
              "      <td>9.8</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>11.2</td>\n",
              "      <td>0.28</td>\n",
              "      <td>0.56</td>\n",
              "      <td>1.9</td>\n",
              "      <td>0.075</td>\n",
              "      <td>17.0</td>\n",
              "      <td>60.0</td>\n",
              "      <td>0.9980</td>\n",
              "      <td>3.16</td>\n",
              "      <td>0.58</td>\n",
              "      <td>9.8</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7.4</td>\n",
              "      <td>0.70</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.9</td>\n",
              "      <td>0.076</td>\n",
              "      <td>11.0</td>\n",
              "      <td>34.0</td>\n",
              "      <td>0.9978</td>\n",
              "      <td>3.51</td>\n",
              "      <td>0.56</td>\n",
              "      <td>9.4</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>7.4</td>\n",
              "      <td>0.66</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.8</td>\n",
              "      <td>0.075</td>\n",
              "      <td>13.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>0.9978</td>\n",
              "      <td>3.51</td>\n",
              "      <td>0.56</td>\n",
              "      <td>9.4</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>7.9</td>\n",
              "      <td>0.60</td>\n",
              "      <td>0.06</td>\n",
              "      <td>1.6</td>\n",
              "      <td>0.069</td>\n",
              "      <td>15.0</td>\n",
              "      <td>59.0</td>\n",
              "      <td>0.9964</td>\n",
              "      <td>3.30</td>\n",
              "      <td>0.46</td>\n",
              "      <td>9.4</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>7.3</td>\n",
              "      <td>0.65</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.2</td>\n",
              "      <td>0.065</td>\n",
              "      <td>15.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>0.9946</td>\n",
              "      <td>3.39</td>\n",
              "      <td>0.47</td>\n",
              "      <td>10.0</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>7.8</td>\n",
              "      <td>0.58</td>\n",
              "      <td>0.02</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.073</td>\n",
              "      <td>9.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>0.9968</td>\n",
              "      <td>3.36</td>\n",
              "      <td>0.57</td>\n",
              "      <td>9.5</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>6.7</td>\n",
              "      <td>0.58</td>\n",
              "      <td>0.08</td>\n",
              "      <td>1.8</td>\n",
              "      <td>0.097</td>\n",
              "      <td>15.0</td>\n",
              "      <td>65.0</td>\n",
              "      <td>0.9959</td>\n",
              "      <td>3.28</td>\n",
              "      <td>0.54</td>\n",
              "      <td>9.2</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-060c880c-b749-4ae2-bfb0-932e60b2efe5')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-060c880c-b749-4ae2-bfb0-932e60b2efe5 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-060c880c-b749-4ae2-bfb0-932e60b2efe5');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 944
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import warnings\n",
        "from sklearn.exceptions import ConvergenceWarning\n",
        "warnings.filterwarnings(action='ignore', category=ConvergenceWarning)  \n",
        "\n",
        "#Load dataset and display sample\n",
        "dataset = pd.read_csv(\"WineQT.csv\")\n",
        "dataset = dataset.drop(\"Id\", axis = 1) #remove id column since not needed for analysis\n",
        "dataset.head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pour l'extrait de code précedent, on ignore les warning de convergence pour rendre l'exécution du code plus claire. C'est pourquoi j'ai décidé de les ignorer. De plus, comme changement de paramètre à l'étape 9 j'avais initialement décider de changer le paramètre 'max_iter', mais après avoir vu que l'effet de celui-ci était minimal, j'ai conclué qu'il n'était pas nécessaire d'afficher ces avertissements"
      ],
      "metadata": {
        "id": "yXtCpDpEQ6d5"
      },
      "id": "yXtCpDpEQ6d5"
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.info()\n",
        "print(len(dataset))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zdkgoluhVbFs",
        "outputId": "f54609c7-38d8-4ef4-fc35-97fcff952c50"
      },
      "id": "zdkgoluhVbFs",
      "execution_count": 945,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1143 entries, 0 to 1142\n",
            "Data columns (total 12 columns):\n",
            " #   Column                Non-Null Count  Dtype  \n",
            "---  ------                --------------  -----  \n",
            " 0   fixed acidity         1143 non-null   float64\n",
            " 1   volatile acidity      1143 non-null   float64\n",
            " 2   citric acid           1143 non-null   float64\n",
            " 3   residual sugar        1143 non-null   float64\n",
            " 4   chlorides             1143 non-null   float64\n",
            " 5   free sulfur dioxide   1143 non-null   float64\n",
            " 6   total sulfur dioxide  1143 non-null   float64\n",
            " 7   density               1143 non-null   float64\n",
            " 8   pH                    1143 non-null   float64\n",
            " 9   sulphates             1143 non-null   float64\n",
            " 10  alcohol               1143 non-null   float64\n",
            " 11  quality               1143 non-null   int64  \n",
            "dtypes: float64(11), int64(1)\n",
            "memory usage: 107.3 KB\n",
            "1143\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dans l'extrait de code précédent on peut facilement voir en comparant la longueur du jeu de données et le nombre de valeurs non-null qu'il n'y a aucune données manquantes."
      ],
      "metadata": {
        "id": "1dw6zlsEVo4s"
      },
      "id": "1dw6zlsEVo4s"
    },
    {
      "cell_type": "code",
      "execution_count": 946,
      "id": "b7f12e71",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        },
        "id": "b7f12e71",
        "outputId": "548fa4c9-d167-4a39-a83b-be70cda1641f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
              "0            7.4              0.70         0.00             1.9      0.076   \n",
              "1            7.8              0.88         0.00             2.6      0.098   \n",
              "2            7.8              0.76         0.04             2.3      0.092   \n",
              "3           11.2              0.28         0.56             1.9      0.075   \n",
              "4            7.4              0.70         0.00             1.9      0.076   \n",
              "5            7.4              0.66         0.00             1.8      0.075   \n",
              "6            7.9              0.60         0.06             1.6      0.069   \n",
              "7            7.3              0.65         0.00             1.2      0.065   \n",
              "8            7.8              0.58         0.02             2.0      0.073   \n",
              "9            6.7              0.58         0.08             1.8      0.097   \n",
              "\n",
              "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
              "0                 11.0                  34.0   0.9978  3.51       0.56   \n",
              "1                 25.0                  67.0   0.9968  3.20       0.68   \n",
              "2                 15.0                  54.0   0.9970  3.26       0.65   \n",
              "3                 17.0                  60.0   0.9980  3.16       0.58   \n",
              "4                 11.0                  34.0   0.9978  3.51       0.56   \n",
              "5                 13.0                  40.0   0.9978  3.51       0.56   \n",
              "6                 15.0                  59.0   0.9964  3.30       0.46   \n",
              "7                 15.0                  21.0   0.9946  3.39       0.47   \n",
              "8                  9.0                  18.0   0.9968  3.36       0.57   \n",
              "9                 15.0                  65.0   0.9959  3.28       0.54   \n",
              "\n",
              "   alcohol    quality  \n",
              "0      9.4       Poor  \n",
              "1      9.8       Poor  \n",
              "2      9.8       Poor  \n",
              "3      9.8       Poor  \n",
              "4      9.4       Poor  \n",
              "5      9.4       Poor  \n",
              "6      9.4       Poor  \n",
              "7     10.0  Excellent  \n",
              "8      9.5  Excellent  \n",
              "9      9.2       Poor  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e88e8196-8a10-4e01-905c-ffae9b4c56c5\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fixed acidity</th>\n",
              "      <th>volatile acidity</th>\n",
              "      <th>citric acid</th>\n",
              "      <th>residual sugar</th>\n",
              "      <th>chlorides</th>\n",
              "      <th>free sulfur dioxide</th>\n",
              "      <th>total sulfur dioxide</th>\n",
              "      <th>density</th>\n",
              "      <th>pH</th>\n",
              "      <th>sulphates</th>\n",
              "      <th>alcohol</th>\n",
              "      <th>quality</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>7.4</td>\n",
              "      <td>0.70</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.9</td>\n",
              "      <td>0.076</td>\n",
              "      <td>11.0</td>\n",
              "      <td>34.0</td>\n",
              "      <td>0.9978</td>\n",
              "      <td>3.51</td>\n",
              "      <td>0.56</td>\n",
              "      <td>9.4</td>\n",
              "      <td>Poor</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>7.8</td>\n",
              "      <td>0.88</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2.6</td>\n",
              "      <td>0.098</td>\n",
              "      <td>25.0</td>\n",
              "      <td>67.0</td>\n",
              "      <td>0.9968</td>\n",
              "      <td>3.20</td>\n",
              "      <td>0.68</td>\n",
              "      <td>9.8</td>\n",
              "      <td>Poor</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>7.8</td>\n",
              "      <td>0.76</td>\n",
              "      <td>0.04</td>\n",
              "      <td>2.3</td>\n",
              "      <td>0.092</td>\n",
              "      <td>15.0</td>\n",
              "      <td>54.0</td>\n",
              "      <td>0.9970</td>\n",
              "      <td>3.26</td>\n",
              "      <td>0.65</td>\n",
              "      <td>9.8</td>\n",
              "      <td>Poor</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>11.2</td>\n",
              "      <td>0.28</td>\n",
              "      <td>0.56</td>\n",
              "      <td>1.9</td>\n",
              "      <td>0.075</td>\n",
              "      <td>17.0</td>\n",
              "      <td>60.0</td>\n",
              "      <td>0.9980</td>\n",
              "      <td>3.16</td>\n",
              "      <td>0.58</td>\n",
              "      <td>9.8</td>\n",
              "      <td>Poor</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7.4</td>\n",
              "      <td>0.70</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.9</td>\n",
              "      <td>0.076</td>\n",
              "      <td>11.0</td>\n",
              "      <td>34.0</td>\n",
              "      <td>0.9978</td>\n",
              "      <td>3.51</td>\n",
              "      <td>0.56</td>\n",
              "      <td>9.4</td>\n",
              "      <td>Poor</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>7.4</td>\n",
              "      <td>0.66</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.8</td>\n",
              "      <td>0.075</td>\n",
              "      <td>13.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>0.9978</td>\n",
              "      <td>3.51</td>\n",
              "      <td>0.56</td>\n",
              "      <td>9.4</td>\n",
              "      <td>Poor</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>7.9</td>\n",
              "      <td>0.60</td>\n",
              "      <td>0.06</td>\n",
              "      <td>1.6</td>\n",
              "      <td>0.069</td>\n",
              "      <td>15.0</td>\n",
              "      <td>59.0</td>\n",
              "      <td>0.9964</td>\n",
              "      <td>3.30</td>\n",
              "      <td>0.46</td>\n",
              "      <td>9.4</td>\n",
              "      <td>Poor</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>7.3</td>\n",
              "      <td>0.65</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.2</td>\n",
              "      <td>0.065</td>\n",
              "      <td>15.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>0.9946</td>\n",
              "      <td>3.39</td>\n",
              "      <td>0.47</td>\n",
              "      <td>10.0</td>\n",
              "      <td>Excellent</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>7.8</td>\n",
              "      <td>0.58</td>\n",
              "      <td>0.02</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.073</td>\n",
              "      <td>9.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>0.9968</td>\n",
              "      <td>3.36</td>\n",
              "      <td>0.57</td>\n",
              "      <td>9.5</td>\n",
              "      <td>Excellent</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>6.7</td>\n",
              "      <td>0.58</td>\n",
              "      <td>0.08</td>\n",
              "      <td>1.8</td>\n",
              "      <td>0.097</td>\n",
              "      <td>15.0</td>\n",
              "      <td>65.0</td>\n",
              "      <td>0.9959</td>\n",
              "      <td>3.28</td>\n",
              "      <td>0.54</td>\n",
              "      <td>9.2</td>\n",
              "      <td>Poor</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e88e8196-8a10-4e01-905c-ffae9b4c56c5')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e88e8196-8a10-4e01-905c-ffae9b4c56c5 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e88e8196-8a10-4e01-905c-ffae9b4c56c5');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 946
        }
      ],
      "source": [
        "#Change quality from multiclass to binary\n",
        "dataset['quality'] = pd.cut(dataset['quality'], bins=[0, 6, 8], labels=['Poor', 'Excellent'])\n",
        "dataset.head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dans l'extrait de code précédent, on change l'attribut de sortie pour un attribut binaire afin d'avoir des résultats plus constants et précis, ainsi que de facilité la tâche et la compréhension du projet en générale."
      ],
      "metadata": {
        "id": "ZXdtPrnHTzs-"
      },
      "id": "ZXdtPrnHTzs-"
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import KFold\n",
        "\n",
        "X = dataset.drop(\"quality\", axis=1).to_numpy() #dataset without output column\n",
        "y = dataset[\"quality\"].to_numpy() #output column\n",
        "\n",
        "#Separation in 10 folds and train/test folds\n",
        "kf = KFold(n_splits=10)\n",
        "for train_index, test_index in kf.split(X):\n",
        "  X_train, X_test = X[train_index], X[test_index]\n",
        "  y_train, y_test = y[train_index], y[test_index]"
      ],
      "metadata": {
        "id": "4zJSIYBJfal8"
      },
      "id": "4zJSIYBJfal8",
      "execution_count": 947,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dans l'extrait de code précédent, on sépare les entrées et la sortie du jeu de données, puis on sépare ceux-ci en 10 différent folds en utilisant les fonctions présentes dans sklearn."
      ],
      "metadata": {
        "id": "qAW-kdSJUPHr"
      },
      "id": "qAW-kdSJUPHr"
    },
    {
      "cell_type": "markdown",
      "id": "de79e3a4",
      "metadata": {
        "id": "de79e3a4"
      },
      "source": [
        "### Étape 6\n",
        "#### a. Entrainement du modèle Naive Bayes (paramètres par défaut)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "gnb = GaussianNB().fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "VfPSS4JbpszQ"
      },
      "id": "VfPSS4JbpszQ",
      "execution_count": 948,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "b. Entrainement du modèle regression logistique (paramètres par défaut)"
      ],
      "metadata": {
        "id": "QhnuFGPHrg-Y"
      },
      "id": "QhnuFGPHrg-Y"
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "log_reg = LogisticRegression().fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "KtuM7NRWriMI"
      },
      "id": "KtuM7NRWriMI",
      "execution_count": 949,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### c. Entrainement du modèle perceptron multicouche (paramètres par défaut)"
      ],
      "metadata": {
        "id": "O8Zf2N71C7gp"
      },
      "id": "O8Zf2N71C7gp"
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "mlp = MLPClassifier().fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "ZbuxFdSXC9kX"
      },
      "id": "ZbuxFdSXC9kX",
      "execution_count": 950,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "840cde86",
      "metadata": {
        "id": "840cde86"
      },
      "source": [
        "### Étape 7 - Test des trois modèles"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gnb_pred = gnb.predict(X_test) #Naive bayes\n",
        "log_reg_pred = log_reg.predict(X_test) #Logistic regression\n",
        "mlp_pred = mlp.predict(X_test) #Multi layer perceptron"
      ],
      "metadata": {
        "id": "kLo1xJRZ1i8a"
      },
      "id": "kLo1xJRZ1i8a",
      "execution_count": 951,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "e4001c6f",
      "metadata": {
        "id": "e4001c6f"
      },
      "source": [
        "### Étape 8 - Mesures de précision"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import recall_score, precision_score, confusion_matrix\n",
        "\n",
        "results = [] #List containing the results of precision and values. See step 10 for format of this list\n",
        "confusion_matrixes = [] #List containing all confusion matrixes. See step 10 for format of this list\n",
        "\n",
        "#Generate confusion matrixes\n",
        "(gnb_confusion_matrix) = confusion_matrix(y_test, gnb_pred).ravel()\n",
        "(log_res_confusion_matrix) = confusion_matrix(y_test, log_reg_pred).ravel()\n",
        "(mlp_confusion_matrix) = confusion_matrix(y_test, mlp_pred).ravel()\n",
        "\n",
        "confusion_matrixes.extend([gnb_confusion_matrix, log_res_confusion_matrix, mlp_confusion_matrix])\n",
        "\n",
        "#Precision and recall measures\n",
        "precision_gnb = precision_score(y_test, gnb_pred, pos_label='Poor')\n",
        "precision_log_res = precision_score(y_test, log_reg_pred, pos_label='Poor')\n",
        "precision_mlp = precision_score(y_test, mlp_pred, pos_label='Poor')\n",
        "\n",
        "recall_gnb = recall_score(y_test, gnb_pred, pos_label='Poor')\n",
        "recall_log_res = recall_score(y_test, log_reg_pred, pos_label='Poor')\n",
        "recall_mlp = recall_score(y_test, mlp_pred, pos_label='Poor')\n",
        "\n",
        "results.append([precision_gnb, precision_log_res, precision_mlp, recall_gnb, recall_log_res, recall_mlp])"
      ],
      "metadata": {
        "id": "g0eNV8C09Zth"
      },
      "id": "g0eNV8C09Zth",
      "execution_count": 952,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "44f3a0b1",
      "metadata": {
        "id": "44f3a0b1"
      },
      "source": [
        "### Étape 9"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Changement 1 - Changement Nombre de folds"
      ],
      "metadata": {
        "id": "DnPrhxeOJq9O"
      },
      "id": "DnPrhxeOJq9O"
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Moins de folds"
      ],
      "metadata": {
        "id": "AlUfAIbTNFy-"
      },
      "id": "AlUfAIbTNFy-"
    },
    {
      "cell_type": "code",
      "execution_count": 953,
      "metadata": {
        "id": "6fa474c0"
      },
      "outputs": [],
      "source": [
        "#Step 5\n",
        "X = dataset.drop(\"quality\", axis=1).to_numpy() #dataset without output column\n",
        "y = dataset[\"quality\"].to_numpy() #output column\n",
        "\n",
        "kf = KFold(n_splits=3)\n",
        "for train_index, test_index in kf.split(X):\n",
        "  X_train, X_test = X[train_index], X[test_index]\n",
        "  y_train, y_test = y[train_index], y[test_index]\n",
        "\n",
        "#Step 6\n",
        "gnb = GaussianNB().fit(X_train, y_train)\n",
        "log_reg = LogisticRegression().fit(X_train, y_train)\n",
        "mlp = MLPClassifier().fit(X_train, y_train)\n",
        "\n",
        "#Step 7\n",
        "gnb_pred = gnb.predict(X_test)\n",
        "log_reg_pred = log_reg.predict(X_test)\n",
        "mlp_pred = mlp.predict(X_test)\n",
        "\n",
        "#Step 8\n",
        "(gnb_confusion_matrix) = confusion_matrix(y_test, gnb_pred).ravel()\n",
        "(log_res_confusion_matrix) = confusion_matrix(y_test, log_reg_pred).ravel()\n",
        "(mlp_confusion_matrix) = confusion_matrix(y_test, mlp_pred).ravel()\n",
        "\n",
        "confusion_matrixes.extend([gnb_confusion_matrix, log_res_confusion_matrix, mlp_confusion_matrix])\n",
        "\n",
        "precision_gnb = precision_score(y_test, gnb_pred, pos_label='Poor')\n",
        "precision_log_res = precision_score(y_test, log_reg_pred, pos_label='Poor')\n",
        "precision_mlp = precision_score(y_test, mlp_pred, pos_label='Poor')\n",
        "\n",
        "recall_gnb = recall_score(y_test, gnb_pred, pos_label='Poor')\n",
        "recall_log_res = recall_score(y_test, log_reg_pred, pos_label='Poor')\n",
        "recall_mlp = recall_score(y_test, mlp_pred, pos_label='Poor')\n",
        "\n",
        "results.append([precision_gnb, precision_log_res, precision_mlp, recall_gnb, recall_log_res, recall_mlp])"
      ],
      "id": "6fa474c0"
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Plus de folds"
      ],
      "metadata": {
        "id": "JliD920-NBV2"
      },
      "id": "JliD920-NBV2"
    },
    {
      "cell_type": "code",
      "execution_count": 954,
      "metadata": {
        "id": "d-kZvk2iMJoL"
      },
      "outputs": [],
      "source": [
        "#Step 5\n",
        "X = dataset.drop(\"quality\", axis=1).to_numpy() #dataset without output column\n",
        "y = dataset[\"quality\"].to_numpy() #output column\n",
        "\n",
        "kf = KFold(n_splits=30)\n",
        "for train_index, test_index in kf.split(X):\n",
        "  X_train, X_test = X[train_index], X[test_index]\n",
        "  y_train, y_test = y[train_index], y[test_index]\n",
        "\n",
        "#Step 6\n",
        "gnb = GaussianNB().fit(X_train, y_train)\n",
        "log_reg = LogisticRegression().fit(X_train, y_train)\n",
        "mlp = MLPClassifier().fit(X_train, y_train)\n",
        "\n",
        "#Step 7\n",
        "gnb_pred = gnb.predict(X_test)\n",
        "log_reg_pred = log_reg.predict(X_test)\n",
        "mlp_pred = mlp.predict(X_test)\n",
        "\n",
        "#Step 8\n",
        "(gnb_confusion_matrix) = confusion_matrix(y_test, gnb_pred).ravel()\n",
        "(log_res_confusion_matrix) = confusion_matrix(y_test, log_reg_pred).ravel()\n",
        "(mlp_confusion_matrix) = confusion_matrix(y_test, mlp_pred).ravel()\n",
        "\n",
        "confusion_matrixes.extend([gnb_confusion_matrix, log_res_confusion_matrix, mlp_confusion_matrix])\n",
        "\n",
        "precision_gnb = precision_score(y_test, gnb_pred, pos_label='Poor')\n",
        "precision_log_res = precision_score(y_test, log_reg_pred, pos_label='Poor')\n",
        "precision_mlp = precision_score(y_test, mlp_pred, pos_label='Poor')\n",
        "\n",
        "recall_gnb = recall_score(y_test, gnb_pred, pos_label='Poor')\n",
        "recall_log_res = recall_score(y_test, log_reg_pred, pos_label='Poor')\n",
        "recall_mlp = recall_score(y_test, mlp_pred, pos_label='Poor')\n",
        "\n",
        "results.append([precision_gnb, precision_log_res, precision_mlp, recall_gnb, recall_log_res, recall_mlp])"
      ],
      "id": "d-kZvk2iMJoL"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Changement 2 - Changement des algorithmes d'entrainement"
      ],
      "metadata": {
        "id": "V7ztV-lCLlCO"
      },
      "id": "V7ztV-lCLlCO"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Naive bayes: Gaussian -> Bernouilli  \n",
        "Regression logistique: lbfgs -> liblinear  \n",
        "MLP: adam -> lbfgs"
      ],
      "metadata": {
        "id": "tNaHfIZtOY-z"
      },
      "id": "tNaHfIZtOY-z"
    },
    {
      "cell_type": "code",
      "execution_count": 955,
      "metadata": {
        "id": "jtAcgBs1Lp0k"
      },
      "outputs": [],
      "source": [
        "#Step 5\n",
        "from sklearn.naive_bayes import BernoulliNB\n",
        "X = dataset.drop(\"quality\", axis=1).to_numpy() #dataset without output column\n",
        "y = dataset[\"quality\"].to_numpy() #output column\n",
        "\n",
        "kf = KFold(n_splits=10)\n",
        "for train_index, test_index in kf.split(X):\n",
        "  X_train, X_test = X[train_index], X[test_index]\n",
        "  y_train, y_test = y[train_index], y[test_index]\n",
        "\n",
        "#Step 6\n",
        "gnb = BernoulliNB().fit(X_train, y_train)\n",
        "log_reg = LogisticRegression(solver='liblinear').fit(X_train, y_train)\n",
        "mlp = MLPClassifier(solver='lbfgs').fit(X_train, y_train)\n",
        "#Step 7\n",
        "gnb_pred = gnb.predict(X_test)\n",
        "log_reg_pred = log_reg.predict(X_test)\n",
        "mlp_pred = mlp.predict(X_test)\n",
        "\n",
        "#Step 8\n",
        "(gnb_confusion_matrix) = confusion_matrix(y_test, gnb_pred).ravel()\n",
        "(log_res_confusion_matrix) = confusion_matrix(y_test, log_reg_pred).ravel()\n",
        "(mlp_confusion_matrix) = confusion_matrix(y_test, mlp_pred).ravel()\n",
        "\n",
        "confusion_matrixes.extend([gnb_confusion_matrix, log_res_confusion_matrix, mlp_confusion_matrix])\n",
        "\n",
        "precision_gnb = precision_score(y_test, gnb_pred, pos_label='Poor')\n",
        "precision_log_res = precision_score(y_test, log_reg_pred, pos_label='Poor')\n",
        "precision_mlp = precision_score(y_test, mlp_pred, pos_label='Poor')\n",
        "\n",
        "recall_gnb = recall_score(y_test, gnb_pred, pos_label='Poor')\n",
        "recall_log_res = recall_score(y_test, log_reg_pred, pos_label='Poor')\n",
        "recall_mlp = recall_score(y_test, mlp_pred, pos_label='Poor')\n",
        "\n",
        "results.append([precision_gnb, precision_log_res, precision_mlp, recall_gnb, recall_log_res, recall_mlp])"
      ],
      "id": "jtAcgBs1Lp0k"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Étape 10 - Analyse des résultats"
      ],
      "metadata": {
        "id": "J8l9woGcWb4_"
      },
      "id": "J8l9woGcWb4_"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### a."
      ],
      "metadata": {
        "id": "blrAFCBfWgA1"
      },
      "id": "blrAFCBfWgA1"
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "resultsnp = np.array(results)\n",
        "df = pd.DataFrame(resultsnp, columns = ['Precision GNB', 'Precision Log Reg','Precision MLP','Recall GNB', 'Recall Log Reg','Recall MLP'])\n",
        "df.index = ['Initial', 'Lower KFolds', 'Higher KFolds', 'Higher max_iter']\n",
        "df\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "TyzM3YaQZ6de",
        "outputId": "0eea2af0-d1a4-456d-acce-bf436b0183e4"
      },
      "id": "TyzM3YaQZ6de",
      "execution_count": 956,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                 Precision GNB  Precision Log Reg  Precision MLP  Recall GNB  \\\n",
              "Initial               0.928571           0.873874       0.882353    0.919192   \n",
              "Lower KFolds          0.947020           0.919308       0.923547    0.851190   \n",
              "Higher KFolds         0.968750           0.972222       0.969697    0.861111   \n",
              "Higher max_iter       0.868421           0.881818       0.928571    1.000000   \n",
              "\n",
              "                 Recall Log Reg  Recall MLP  \n",
              "Initial                0.979798    0.909091  \n",
              "Lower KFolds           0.949405    0.898810  \n",
              "Higher KFolds          0.972222    0.888889  \n",
              "Higher max_iter        0.979798    0.919192  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d1b74735-0930-4e95-9493-fb9e77474093\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Precision GNB</th>\n",
              "      <th>Precision Log Reg</th>\n",
              "      <th>Precision MLP</th>\n",
              "      <th>Recall GNB</th>\n",
              "      <th>Recall Log Reg</th>\n",
              "      <th>Recall MLP</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Initial</th>\n",
              "      <td>0.928571</td>\n",
              "      <td>0.873874</td>\n",
              "      <td>0.882353</td>\n",
              "      <td>0.919192</td>\n",
              "      <td>0.979798</td>\n",
              "      <td>0.909091</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Lower KFolds</th>\n",
              "      <td>0.947020</td>\n",
              "      <td>0.919308</td>\n",
              "      <td>0.923547</td>\n",
              "      <td>0.851190</td>\n",
              "      <td>0.949405</td>\n",
              "      <td>0.898810</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Higher KFolds</th>\n",
              "      <td>0.968750</td>\n",
              "      <td>0.972222</td>\n",
              "      <td>0.969697</td>\n",
              "      <td>0.861111</td>\n",
              "      <td>0.972222</td>\n",
              "      <td>0.888889</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Higher max_iter</th>\n",
              "      <td>0.868421</td>\n",
              "      <td>0.881818</td>\n",
              "      <td>0.928571</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.979798</td>\n",
              "      <td>0.919192</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d1b74735-0930-4e95-9493-fb9e77474093')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d1b74735-0930-4e95-9493-fb9e77474093 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d1b74735-0930-4e95-9493-fb9e77474093');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 956
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dans le tableau ci-dessus se retrouve les valeurs de précision et de rappel pour l'analyse initial, celle avec moins de kfolds, celle avec plus de kfold et celle pour un nombre d'itération maximale plus grand. L'analyse de ces résultats sera fait dans les prochains éléments du rapport étant donné qu'il peut être difficile d'analyser ces chiffres dans un simple tableau."
      ],
      "metadata": {
        "id": "Gq4-dOhfKCnR"
      },
      "id": "Gq4-dOhfKCnR"
    },
    {
      "cell_type": "code",
      "source": [
        "#Compare effect of variation of number of Kfolds\n",
        "resultsnp_kfold = np.delete(resultsnp, 3, 0)\n",
        "resultsnp_kfold = np.transpose(resultsnp_kfold)\n",
        "df = pd.DataFrame(resultsnp_kfold, columns = ['Initial', 'Lower KFolds', 'Higher KFolds'])\n",
        "df.index = ['Precision GNB', 'Precision Log Reg','Precision MLP','Recall GNB', 'Recall Log Reg','Recall MLP']\n",
        "df.plot.bar().legend(loc='center left',bbox_to_anchor=(1.0, 0.5))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 360
        },
        "id": "EHnaMI0Ftw3v",
        "outputId": "22b6d628-0455-4882-9262-18532cd27f90"
      },
      "id": "EHnaMI0Ftw3v",
      "execution_count": 957,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7fc7bfe7a5d0>"
            ]
          },
          "metadata": {},
          "execution_count": 957
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "En observant le graphique ci-dessus, certaines observations importantes peuvent être faits.  \n",
        "Premièrement, on remarque que pour une plus grand nombre de kfold, la precision est définitivement plus favorable, alors que le rappel est définitivement moins bon.  \n",
        "Pour un moins grand nombre de kfolds, la même observation peut être faite. Par contre, on remarque que la différence est moins évidente.  \n",
        "On peut conclure qu'il pourrait avoir un juste milieu de nombre de kfolds (entre 10 et 30 pour notre cas), afin d'équilibrer les valeurs de la précision et du rappel pour avoir des résultats les plus optimales possibles.  \n",
        "Après avoir complété le projet, je remarque que peut-être la grandeur de mon jeu de données aurait pu être plus grande afin d'avoir des résultats plus concluants. Il serait intéressant de refaire l'expérience avec une différente taille de jeu de données."
      ],
      "metadata": {
        "id": "P7WSZkzAKjKP"
      },
      "id": "P7WSZkzAKjKP"
    },
    {
      "cell_type": "code",
      "source": [
        "#Compare effect of alternative algorithm\n",
        "resultsnp_max_iter = np.delete(resultsnp, 1, 0)\n",
        "resultsnp_max_iter = np.delete(resultsnp_max_iter, 1, 0)\n",
        "resultsnp_max_iter = np.transpose(resultsnp_max_iter)\n",
        "resultsnp_max_iter.shape\n",
        "df = pd.DataFrame(resultsnp_max_iter, columns = ['Initial', 'Alternative algorithm'])\n",
        "df.index = ['Precision GNB', 'Precision Log Reg','Precision MLP','Recall GNB', 'Recall Log Reg','Recall MLP']\n",
        "df.plot.bar().legend(loc='center left',bbox_to_anchor=(1.0, 0.5))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 360
        },
        "outputId": "d4e5783e-b9a7-4483-bee1-0c80f3378500",
        "id": "acP97aKbwiyD"
      },
      "execution_count": 958,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7fc7bfc1ad90>"
            ]
          },
          "metadata": {},
          "execution_count": 958
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "id": "acP97aKbwiyD"
    },
    {
      "cell_type": "markdown",
      "source": [
        "En observant le graphique ci-dessus, certaines observations importantes peuvent être faits.  \n",
        "Premièrement il est évident que certains algorithmes sont favorables tout dépendant du format du jeu de données qui est utilisé (taille, attribut, binaire ou multiclasse, etc.)  \n",
        "Dans mon cas, on peut affirmer que l'algorithme Naive Bayes de Bernouilli est plus efficace pour le rappel mais pas la précision, que le choix d'algorithme pour la régression logistique a peu d'impact sur le rappel et la précision et que l'algorithme 'lbfgs' (famille des methodes quasi-Newton) à un leger impact positif siur nos mesures de rappel et de précision."
      ],
      "metadata": {
        "id": "9Gg9n2RELk_k"
      },
      "id": "9Gg9n2RELk_k"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### b.\n"
      ],
      "metadata": {
        "id": "GaEqnFqGW36o"
      },
      "id": "GaEqnFqGW36o"
    },
    {
      "cell_type": "code",
      "source": [
        "#Data manipalution to display all confusion matrixes\n",
        "cmnp = np.array(confusion_matrixes)\n",
        "models = ['NB', 'LR', 'MLP']\n",
        "changes = ['initial', 'lower_kfolds', 'higher_kfolds', 'alt_algo']\n",
        "indexes = []\n",
        "df = pd.DataFrame(cmnp, columns = ['True negative', 'False Positive','False Negative','True Positive'])\n",
        "for c in changes:\n",
        "  for m in models:\n",
        "    indexes.append(f'{m}_{c}')\n",
        "df.index = indexes\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 426
        },
        "id": "SPH98psfDSn3",
        "outputId": "c8a1e8c0-4ecf-408b-c6f1-8519f2ea2408"
      },
      "id": "SPH98psfDSn3",
      "execution_count": 959,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                   True negative  False Positive  False Negative  \\\n",
              "NB_initial                     8               7               8   \n",
              "LR_initial                     1              14               2   \n",
              "MLP_initial                    3              12               9   \n",
              "NB_lower_kfolds               29              16              50   \n",
              "LR_lower_kfolds               17              28              17   \n",
              "MLP_lower_kfolds              20              25              34   \n",
              "NB_higher_kfolds               1               1               5   \n",
              "LR_higher_kfolds               1               1               1   \n",
              "MLP_higher_kfolds              1               1               4   \n",
              "NB_alt_algo                    0              15               0   \n",
              "LR_alt_algo                    2              13               2   \n",
              "MLP_alt_algo                   8               7               8   \n",
              "\n",
              "                   True Positive  \n",
              "NB_initial                    91  \n",
              "LR_initial                    97  \n",
              "MLP_initial                   90  \n",
              "NB_lower_kfolds              286  \n",
              "LR_lower_kfolds              319  \n",
              "MLP_lower_kfolds             302  \n",
              "NB_higher_kfolds              31  \n",
              "LR_higher_kfolds              35  \n",
              "MLP_higher_kfolds             32  \n",
              "NB_alt_algo                   99  \n",
              "LR_alt_algo                   97  \n",
              "MLP_alt_algo                  91  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-657e1013-5c51-4c30-946b-3fb2527e87c1\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>True negative</th>\n",
              "      <th>False Positive</th>\n",
              "      <th>False Negative</th>\n",
              "      <th>True Positive</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>NB_initial</th>\n",
              "      <td>8</td>\n",
              "      <td>7</td>\n",
              "      <td>8</td>\n",
              "      <td>91</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LR_initial</th>\n",
              "      <td>1</td>\n",
              "      <td>14</td>\n",
              "      <td>2</td>\n",
              "      <td>97</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MLP_initial</th>\n",
              "      <td>3</td>\n",
              "      <td>12</td>\n",
              "      <td>9</td>\n",
              "      <td>90</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NB_lower_kfolds</th>\n",
              "      <td>29</td>\n",
              "      <td>16</td>\n",
              "      <td>50</td>\n",
              "      <td>286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LR_lower_kfolds</th>\n",
              "      <td>17</td>\n",
              "      <td>28</td>\n",
              "      <td>17</td>\n",
              "      <td>319</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MLP_lower_kfolds</th>\n",
              "      <td>20</td>\n",
              "      <td>25</td>\n",
              "      <td>34</td>\n",
              "      <td>302</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NB_higher_kfolds</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LR_higher_kfolds</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>35</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MLP_higher_kfolds</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>32</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NB_alt_algo</th>\n",
              "      <td>0</td>\n",
              "      <td>15</td>\n",
              "      <td>0</td>\n",
              "      <td>99</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LR_alt_algo</th>\n",
              "      <td>2</td>\n",
              "      <td>13</td>\n",
              "      <td>2</td>\n",
              "      <td>97</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MLP_alt_algo</th>\n",
              "      <td>8</td>\n",
              "      <td>7</td>\n",
              "      <td>8</td>\n",
              "      <td>91</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-657e1013-5c51-4c30-946b-3fb2527e87c1')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-657e1013-5c51-4c30-946b-3fb2527e87c1 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-657e1013-5c51-4c30-946b-3fb2527e87c1');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 959
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dans le tableau ci-dessus, on peut voir les valeurs des matrices de confusion pour les différents modèles et changement porter à ceux-ci. Pour cette expérimentation, la valeur 'Poor' est considérer comme un positif, et 'Excellent' comme un négatif. J'aurais pu faire l'inverse aussi, peu importe. "
      ],
      "metadata": {
        "id": "A7Cy-aOxPDTC"
      },
      "id": "A7Cy-aOxPDTC"
    },
    {
      "cell_type": "code",
      "source": [
        "compare = mlp_pred, y_test\n",
        "compare = np.transpose(compare)\n",
        "df = pd.DataFrame(compare, columns = ['mlp_pred', 'y_test'])\n",
        "df.head(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "8WZL16U8QHcb",
        "outputId": "17f1b2b5-005a-4a33-8cd5-e5da523ab483"
      },
      "id": "8WZL16U8QHcb",
      "execution_count": 960,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    mlp_pred     y_test\n",
              "0       Poor       Poor\n",
              "1  Excellent  Excellent\n",
              "2  Excellent  Excellent\n",
              "3  Excellent  Excellent\n",
              "4       Poor  Excellent\n",
              "5       Poor       Poor\n",
              "6       Poor       Poor\n",
              "7       Poor       Poor\n",
              "8       Poor       Poor\n",
              "9  Excellent  Excellent"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-349fa0ac-9dca-4938-8a84-530cca644fef\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mlp_pred</th>\n",
              "      <th>y_test</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Poor</td>\n",
              "      <td>Poor</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Excellent</td>\n",
              "      <td>Excellent</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Excellent</td>\n",
              "      <td>Excellent</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Excellent</td>\n",
              "      <td>Excellent</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Poor</td>\n",
              "      <td>Excellent</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Poor</td>\n",
              "      <td>Poor</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Poor</td>\n",
              "      <td>Poor</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Poor</td>\n",
              "      <td>Poor</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Poor</td>\n",
              "      <td>Poor</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Excellent</td>\n",
              "      <td>Excellent</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-349fa0ac-9dca-4938-8a84-530cca644fef')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-349fa0ac-9dca-4938-8a84-530cca644fef button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-349fa0ac-9dca-4938-8a84-530cca644fef');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 960
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dans ce petit échantillon ayant été tester avec 10 folds, le perceptron multlicouche avec l'algorithme 'lbfgs' on peut voir trois faux positif (1,2 et 4, peut être différent si le code est réexecuter), c'est-à-dire que l'on prédit 'Poor', alors que le résultat devrait être excellent.  \n",
        "Ce genre d'anomalie peut arriver pour plusieurs raisons, mais dans notre cas on peut conclure que c'est principalement dû à la petite taille de notre jeu de données. Étant donné que la taille du jeu de données est plus petite, le modèle de perceptron multicouche peut ne pas avoir détecter ce \"pattern\" dans les échantillons d'entrainement."
      ],
      "metadata": {
        "id": "lokl08eTSD_n"
      },
      "id": "lokl08eTSD_n"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Référence\n",
        "\n",
        "Tous les fonctions et les explications de ceux-ci on été pris directement de la documentation officielle de sklearn, numpy et panda aux liens suivants: scikit-learn.org, numpy.org, pandas.pydata.org"
      ],
      "metadata": {
        "id": "TATIgFnRYfXa"
      },
      "id": "TATIgFnRYfXa"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}